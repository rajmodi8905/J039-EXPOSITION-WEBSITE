[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Quarto Blog",
    "section": "",
    "text": "1. Basic Operations\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSimple Visualisation\n\n\n\n\n\n\nML\n\n\n\n\n\n\n\n\n\nFeb 14, 2025\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome\n\n\n\n\n\nWelcome Post\n\n\n\n\n\nFeb 14, 2025\n\n\nNipun Batra\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/welcome.html",
    "href": "posts/welcome.html",
    "title": "Welcome",
    "section": "",
    "text": "Welcome\nHello world, this is my first blog post.\nI can write in markdown\nprint(\"Hello World\")\nI can also write math equations:\n\\[\ny = x^2\n\\]\nI can create lists easily:\n\nOne\nTwo\n\nI can also create numbered lists:\n\nOne\nTwo\n\nOr, create a table:\n\n\n\nName\nAge\n\n\n\n\nAlice\n20\n\n\nBob\n21"
  },
  {
    "objectID": "posts/visualisation.html",
    "href": "posts/visualisation.html",
    "title": "Simple Visualisation",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\n\nx = np.linspace(0, 10, 100)\ny = np.sin(x)\n\nplt.plot(x, y)"
  },
  {
    "objectID": "posts/Assignment_2_Pandas_Matplotlib.html",
    "href": "posts/Assignment_2_Pandas_Matplotlib.html",
    "title": "1. Basic Operations",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import LinearSegmentedColormap\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\n%config inlineBackend.figure_format = 'retina'\nQ1. Write code to create a DataFrame from a dictionary containing student names and their scores in three subjects (Math, Science, English). * Write a code to add a new column Total Marks, which calculates the total marks for each student. * Print first five rows of the DataFrame and summary statistics using the describe() method.\ndf_students = pd.DataFrame(data = {\n    'Name': ['Virat', 'Dhoni', 'Rohit', 'Sachin', 'Gavaskar'],\n    'Math': [90, 80, 85, 70, 95],\n    'Science': [85, 88, 90, 75, 92],\n    'English': [78, 85, 82, 90, 88]\n})\n\ndf_students.eval('Total_Marks = (Math + Science + English)', inplace=True)\n\nprint(f\"First five rows of the DataFrame:\\n {df_students.head()}\\n\")\nprint(f\"Summary statistics of :\\n {df_students.describe()}\")\n\nFirst five rows of the DataFrame:\n        Name  Math  Science  English  Total_Marks\n0     Virat    90       85       78          253\n1     Dhoni    80       88       85          253\n2     Rohit    85       90       82          257\n3    Sachin    70       75       90          235\n4  Gavaskar    95       92       88          275\n\nSummary statistics of :\n             Math    Science    English  Total_Marks\ncount   5.000000   5.000000   5.000000     5.000000\nmean   84.000000  86.000000  84.600000   254.600000\nstd     9.617692   6.670832   4.774935    14.240786\nmin    70.000000  75.000000  78.000000   235.000000\n25%    80.000000  85.000000  82.000000   253.000000\n50%    85.000000  88.000000  85.000000   253.000000\n75%    90.000000  90.000000  88.000000   257.000000\nmax    95.000000  92.000000  90.000000   275.000000\nQ2 Create a dummy CSV file named students.csv containing the following columns: Name, Age, Gender, and Marks (atleast 5 entries). Perform the following tasks:\ncsv_df = pd.read_csv(\"students.csv\")\n\nprint(csv_df.tail(3),\"\\n\")\n\nrows = csv_df.shape[0]\ncolumns = csv_df.shape[1]\n\nprint(f\"Total Rows: {rows}\")\nprint(f\"Total Columns: {columns}\")\n\n            Name  Age  Gender  Marks\n2   Mark Johnson   16    Male     78\n3    Emily Davis   15  Female     88\n4  Michael Brown   17    Male     76 \n\nTotal Rows: 5\nTotal Columns: 4\nQ3.Create and populate a DataFrame with columns Employee_ID, Name, Department, and Salary. Now perform the following:\ndata = {\n    'Employee_ID': ['E1', 'E2', 'E3', 'E4', 'E5'],\n    'Name': ['Bhavya', 'Heer', 'Raj', 'Harsh', 'Aayush'],\n    'Department': ['HR', 'IT', 'Finance', 'IT', 'HR'],\n    'Salary': [50000, 60000, 55000, 58000, 52000],\n}\n\ndf = pd.DataFrame(data)\ndf['Bonus'] = df['Salary']*0.1\ndf['Salary'] += df['Salary']*0.2\nprint(df.drop('Department', axis = 1))\n\n  Employee_ID    Name   Salary   Bonus\n0          E1  Bhavya  60000.0  5000.0\n1          E2    Heer  72000.0  6000.0\n2          E3     Raj  66000.0  5500.0\n3          E4   Harsh  69600.0  5800.0\n4          E5  Aayush  62400.0  5200.0"
  },
  {
    "objectID": "posts/Assignment_2_Pandas_Matplotlib.html#handling-missing-data",
    "href": "posts/Assignment_2_Pandas_Matplotlib.html#handling-missing-data",
    "title": "1. Basic Operations",
    "section": "4. Handling Missing Data",
    "text": "4. Handling Missing Data\nYou are provided with a dataset, numeric_df, containing numeric features from the Titanic dataset. Your task is to explore and handle the missing data systematically.\n\n# Load the Titanic dataset\ndf = sns.load_dataset('titanic')\n\n# Select only numeric columns\nnumeric_df = df.select_dtypes(include = ['float64', 'int64'])\n\n# Introducing missing values in the 'pclass' column\nnp.random.seed(42)\npclass_nan_indices = np.random.choice(numeric_df.index, size = int(0.05 * len(numeric_df)), replace = False)\nnumeric_df.loc[pclass_nan_indices, 'pclass'] = np.nan\n\n# Introducing missing values in the 'parch' column\nparch_nan_indices = np.random.choice(numeric_df.index, size = int(0.70 * len(numeric_df)), replace = False)\nnumeric_df.loc[parch_nan_indices, 'parch'] = np.nan\n\nQ1. Load and Inspect the Data - Run the cell below to get the dataset numeric_df. - Display the first 5 rows of the dataset. - Create a heatmap to visualize where the missing values occur. - Count the missing values in each column and report them (also, plot them). - Drop the column with more than 60 percent NaN values. Why?\n\nprint(f\"The first 5 rows are : \\n{numeric_df.head(5)}\\n\")\n\nheat_map = sns.heatmap(numeric_df, cmap=\"coolwarm\")\nplt.show()                                    #the missing values are the white strips\n\n#missing values\nmissing = numeric_df.isnull().sum()\n\nmissing.plot(kind = \"bar\", xlabel = \"Column Name\", ylabel = \"No. of Missing Values\", title = \"Missing Values in Each Column\")\n\n\nprint(f\"\\nThe missing values per column is :\\n{missing}\\n\")\n\nperc_missing = missing/len(numeric_df)\ndropped_df = numeric_df.loc[:,perc_missing &lt;= 0.6]\n\nprint(f\"The dataframe after dropping columns with more than 60% NaN are : \\n{dropped_df}\\n\")\n\n#It is a common rule in data cleaning as if we imputate columns with more 60% NaN values, then it may introduce biasness and inaccuracy\n\nThe first 5 rows are : \n   survived  pclass   age  sibsp  parch     fare\n0         0     3.0  22.0      1    0.0   7.2500\n1         1     1.0  38.0      1    NaN  71.2833\n2         1     3.0  26.0      0    NaN   7.9250\n3         1     1.0  35.0      1    0.0  53.1000\n4         0     3.0  35.0      0    0.0   8.0500\n\n\n\n\n\n\n\n\n\n\n\nThe missing values per column is :\nsurvived      0\npclass       44\nage         177\nsibsp         0\nparch       623\nfare          0\ndtype: int64\n\nThe dataframe after dropping columns with more than 60% NaN are : \n     survived  pclass   age  sibsp     fare\n0           0     3.0  22.0      1   7.2500\n1           1     1.0  38.0      1  71.2833\n2           1     3.0  26.0      0   7.9250\n3           1     1.0  35.0      1  53.1000\n4           0     3.0  35.0      0   8.0500\n..        ...     ...   ...    ...      ...\n886         0     NaN  27.0      0  13.0000\n887         1     1.0  19.0      0  30.0000\n888         0     3.0   NaN      1  23.4500\n889         1     1.0  26.0      0  30.0000\n890         0     3.0  32.0      0   7.7500\n\n[891 rows x 5 columns]\n\n\n\n\n\n\n\n\n\n\nQ2 Handle Missing Values - For the pclass column, use mode imputation to fill the missing values. - Explain why mode imputation is appropriate for this column.\n\nHow would you impute the values for the column age. Why?\n\n\n\nmeans_before = numeric_df.mean()\n\nmode_of_pclass = numeric_df[\"pclass\"].mode()[0]\nnumeric_df[\"pclass\"] = numeric_df[\"pclass\"].fillna(mode_of_pclass)\n\nprint(numeric_df[\"pclass\"])\n\n#why mode imputation is appropriate for this column? .\n#The main reason to use \"mode\" imputation for the column pclass is as mode imputation retains the most frequent value and this reduces the distortion in our column pclass.\n\n\n#3rd subquestion answered on next cell\n\n0      3.0\n1      1.0\n2      3.0\n3      1.0\n4      3.0\n      ... \n886    3.0\n887    1.0\n888    3.0\n889    1.0\n890    3.0\nName: pclass, Length: 891, dtype: float64\n\n\n\n#now first plotting a histrogram of the column age to check if the distribution is skewed or normal\n\nplt.hist(numeric_df[\"age\"])\n\n(array([ 54.,  46., 177., 169., 118.,  70.,  45.,  24.,   9.,   2.]),\n array([ 0.42 ,  8.378, 16.336, 24.294, 32.252, 40.21 , 48.168, 56.126,\n        64.084, 72.042, 80.   ]),\n &lt;BarContainer object of 10 artists&gt;)\n\n\n\n\n\n\n\n\n\n\n#as seen the distrubution is somewhat normal (looking like a bell curve)\n#therefore using the median imputation would be ideal the column \"age\", as it is mostly skewed by younger age poeple.\n\nmedian_of_age = numeric_df[\"age\"].median()\nnumeric_df[\"age\"] = numeric_df[\"age\"].fillna(median_of_age)\n\nprint(f\"The imputed age column :\\n {numeric_df[\"age\"]}\\n\")\n\nThe imputed age column :\n 0      22.0\n1      38.0\n2      26.0\n3      35.0\n4      35.0\n       ... \n886    27.0\n887    19.0\n888    28.0\n889    26.0\n890    32.0\nName: age, Length: 891, dtype: float64\n\n\n\nQ3 Analyze Results - Compare the dataset before and after imputation: - Count the missing values after imputation. - Calculate the mean of all numeric columns before and after imputation.\n\n\nmissing_val = numeric_df.isnull().sum()\nprint(f\"Missing value: {missing_val}\\n\")\n\nmeans_after = numeric_df.mean()\n\nprint(f\"The means before imputation for all columns :\\n{means_before}\\n\")\nprint(f\"The means after imputation for all coumns : \\n{means_after}\\n\")\n\nMissing value: survived      0\npclass        0\nage           0\nsibsp         0\nparch       623\nfare          0\ndtype: int64\n\nThe means before imputation for all columns :\nsurvived     0.383838\npclass       2.340067\nage         29.699118\nsibsp        0.523008\nparch        0.399254\nfare        32.204208\ndtype: float64\n\nThe means after imputation for all coumns : \nsurvived     0.383838\npclass       2.340067\nage         29.361582\nsibsp        0.523008\nparch        0.399254\nfare        32.204208\ndtype: float64"
  },
  {
    "objectID": "posts/Assignment_2_Pandas_Matplotlib.html#pandas-merging-joining-and-concatenation",
    "href": "posts/Assignment_2_Pandas_Matplotlib.html#pandas-merging-joining-and-concatenation",
    "title": "1. Basic Operations",
    "section": "5. Pandas: Merging Joining and Concatenation",
    "text": "5. Pandas: Merging Joining and Concatenation\nQ1.You have two DataFrames df1 and df2 where df1 has a column student_id and df2 has a column student_id along with grade, how would you merge these DataFrames on student_id to keep only the rows present in both DataFrames? Show output of the merge.\ndata1 = {\n    'student_id': [1, 2, 3, 4],\n    'name': ['Alice', 'Bob', 'Charlie', 'David']\n}\ndata2 = {\n    'student_id': [2, 3, 4, 5],\n    'grade': ['A', 'B', 'C', 'D']\n}\n\ndf1 = pd.DataFrame(data1)\ndf2 = pd.DataFrame(data2)\n\n::: {#cell-35 .cell outputId='9517ee49-2503-4a71-b5c2-0f0f62f4846f' execution_count=329}\n``` {.python .cell-code}\ndata1 = {\n    'student_id': [1, 2, 3, 4],\n    'name': ['Alice', 'Bob', 'Charlie', 'David']\n}\ndata2 = {\n    'student_id': [2, 3, 4, 5],\n    'grade': ['A', 'B', 'C', 'D']\n}\n\ndf1 = pd.DataFrame(data1)\ndf2 = pd.DataFrame(data2)\n\npd.merge(df1, df2, how = \"outer\")\n\n\n\n\n\n\n\n\nstudent_id\nname\ngrade\n\n\n\n\n0\n1\nAlice\nNaN\n\n\n1\n2\nBob\nA\n\n\n2\n3\nCharlie\nB\n\n\n3\n4\nDavid\nC\n\n\n4\n5\nNaN\nD\n\n\n\n\n\n\n:::\nQ2.If you are provided with two DataFrames, employees and departments with employee_id as the index, how would you join them such that all rows from the employees DataFrame are kept, even if there is no matching department record? (you may assume employees have 2nd column as employee_name and departments have 2nd column as department_name, and randomly assign its data)\nemployees_data = {\n    'employee_id': [1, 2, 3, 4],\n    'employee_name': ['Alice', 'Bob', 'Charlie', 'David']\n}\ndepartments_data = {\n    'employee_id': [2, 3, 4, 1],\n    'department_name': ['A', 'B', 'C', 'D']\n}\n\nemployees = pd.DataFrame(employees_data)\ndepartments = pd.DataFrame(departments_data)\n\nemployees_data = {\n    'employee_id': [1, 2, 3, 4],\n    'employee_name': ['Alice', 'Bob', 'Charlie', 'David']\n}\ndepartments_data = {\n    'employee_id': [2, 3, 4, 1],\n    'department_name': ['A', 'B', 'C', 'D']\n}\n\nemployees = pd.DataFrame(employees_data)\ndepartments = pd.DataFrame(departments_data)\n\npd.merge(employees, departments, how = 'left', on = \"employee_id\")    # how = left  keeps the rows from the left dataframe and add the similar ones from the right.\n\n\n\n\n\n\n\n\nemployee_id\nemployee_name\ndepartment_name\n\n\n\n\n0\n1\nAlice\nD\n\n\n1\n2\nBob\nA\n\n\n2\n3\nCharlie\nB\n\n\n3\n4\nDavid\nC\n\n\n\n\n\n\n\nQ3. Given two DataFrames df_a and df_b with the same columns, how would you concatenate them vertically, resetting the index so it starts from zero in the combined DataFrame? (you may assume both dataframes have 2 columns each, and randomly assign its data)\ndf1 = {\n    'student_id': [1, 2, 3, 4],\n    'name': ['Alice', 'Bob', 'Charlie', 'David']\n}\ndf2 = {\n    'student_id': [5, 6, 7, 8],\n    'name': ['Anish', 'Divakar', 'Vaibhav', 'Tanvi']\n}\n\ndf_a = pd.DataFrame(df1)\ndf_b = pd.DataFrame(df2)\n\ndf1 = {\n    'student_id': [1, 2, 3, 4],\n    'name': ['Alice', 'Bob', 'Charlie', 'David']\n}\ndf2 = {\n    'student_id': [5, 6, 7, 8],\n    'name': ['Anish', 'Divakar', 'Vaibhav', 'Tanvi']\n}\n\ndf_a = pd.DataFrame(df1)\ndf_b = pd.DataFrame(df2)\n\npd.concat([df_a, df_b], axis = 0, ignore_index = True)\n\n\n\n\n\n\n\n\nstudent_id\nname\n\n\n\n\n0\n1\nAlice\n\n\n1\n2\nBob\n\n\n2\n3\nCharlie\n\n\n3\n4\nDavid\n\n\n4\n5\nAnish\n\n\n5\n6\nDivakar\n\n\n6\n7\nVaibhav\n\n\n7\n8\nTanvi"
  },
  {
    "objectID": "posts/Assignment_2_Pandas_Matplotlib.html#pandas-advanced-operations-evaluation-and-query",
    "href": "posts/Assignment_2_Pandas_Matplotlib.html#pandas-advanced-operations-evaluation-and-query",
    "title": "1. Basic Operations",
    "section": "6. Pandas: Advanced Operations (Evaluation and Query)",
    "text": "6. Pandas: Advanced Operations (Evaluation and Query)\nYou are provided with the dataset, iris, which contains information about iris flower species and their physical measurements. Your task is to use :\nQ1 Pandas advanced operations such as evaluation (eval) and conditional querying (query) to analyze and extract insights from the dataset.\nQ2 Load and Inspect the Data - Run iris = sns.load_dataset('iris') to load the dataset. - Display the first 5 rows of the dataset. - Print the summary statistics of the dataset.\n\niris = sns.load_dataset('iris')\n\nprint(f\"The first 5 row are : \\n{iris.head(5)}\\n\")\nprint(f\"\\nThe descriptiona about iris is:\\n{iris.describe()}\\n\")\n\nThe first 5 row are : \n   sepal_length  sepal_width  petal_length  petal_width species\n0           5.1          3.5           1.4          0.2  setosa\n1           4.9          3.0           1.4          0.2  setosa\n2           4.7          3.2           1.3          0.2  setosa\n3           4.6          3.1           1.5          0.2  setosa\n4           5.0          3.6           1.4          0.2  setosa\n\n\nThe descriptiona about iris is:\n       sepal_length  sepal_width  petal_length  petal_width\ncount    150.000000   150.000000    150.000000   150.000000\nmean       5.843333     3.057333      3.758000     1.199333\nstd        0.828066     0.435866      1.765298     0.762238\nmin        4.300000     2.000000      1.000000     0.100000\n25%        5.100000     2.800000      1.600000     0.300000\n50%        5.800000     3.000000      4.350000     1.300000\n75%        6.400000     3.300000      5.100000     1.800000\nmax        7.900000     4.400000      6.900000     2.500000\n\n\n\nQ3 Filter the Data Using query - Use the query method to: 1. Find all flowers with a sepal_length&gt; 6.5 and a petal_length &gt; 5. 2. Find all virginica flowers with a petal_width less than 2.\n\niris_1 = iris.query(\"sepal_length &gt; 6.5\" and \"petal_length &gt;5\" and \"petal_width &lt; 2\" and \"species == 'virginica' \")\niris_1\n\n\n\n\n\n\n\n\nsepal_length\nsepal_width\npetal_length\npetal_width\nspecies\n\n\n\n\n100\n6.3\n3.3\n6.0\n2.5\nvirginica\n\n\n101\n5.8\n2.7\n5.1\n1.9\nvirginica\n\n\n102\n7.1\n3.0\n5.9\n2.1\nvirginica\n\n\n103\n6.3\n2.9\n5.6\n1.8\nvirginica\n\n\n104\n6.5\n3.0\n5.8\n2.2\nvirginica\n\n\n105\n7.6\n3.0\n6.6\n2.1\nvirginica\n\n\n106\n4.9\n2.5\n4.5\n1.7\nvirginica\n\n\n107\n7.3\n2.9\n6.3\n1.8\nvirginica\n\n\n108\n6.7\n2.5\n5.8\n1.8\nvirginica\n\n\n109\n7.2\n3.6\n6.1\n2.5\nvirginica\n\n\n110\n6.5\n3.2\n5.1\n2.0\nvirginica\n\n\n111\n6.4\n2.7\n5.3\n1.9\nvirginica\n\n\n112\n6.8\n3.0\n5.5\n2.1\nvirginica\n\n\n113\n5.7\n2.5\n5.0\n2.0\nvirginica\n\n\n114\n5.8\n2.8\n5.1\n2.4\nvirginica\n\n\n115\n6.4\n3.2\n5.3\n2.3\nvirginica\n\n\n116\n6.5\n3.0\n5.5\n1.8\nvirginica\n\n\n117\n7.7\n3.8\n6.7\n2.2\nvirginica\n\n\n118\n7.7\n2.6\n6.9\n2.3\nvirginica\n\n\n119\n6.0\n2.2\n5.0\n1.5\nvirginica\n\n\n120\n6.9\n3.2\n5.7\n2.3\nvirginica\n\n\n121\n5.6\n2.8\n4.9\n2.0\nvirginica\n\n\n122\n7.7\n2.8\n6.7\n2.0\nvirginica\n\n\n123\n6.3\n2.7\n4.9\n1.8\nvirginica\n\n\n124\n6.7\n3.3\n5.7\n2.1\nvirginica\n\n\n125\n7.2\n3.2\n6.0\n1.8\nvirginica\n\n\n126\n6.2\n2.8\n4.8\n1.8\nvirginica\n\n\n127\n6.1\n3.0\n4.9\n1.8\nvirginica\n\n\n128\n6.4\n2.8\n5.6\n2.1\nvirginica\n\n\n129\n7.2\n3.0\n5.8\n1.6\nvirginica\n\n\n130\n7.4\n2.8\n6.1\n1.9\nvirginica\n\n\n131\n7.9\n3.8\n6.4\n2.0\nvirginica\n\n\n132\n6.4\n2.8\n5.6\n2.2\nvirginica\n\n\n133\n6.3\n2.8\n5.1\n1.5\nvirginica\n\n\n134\n6.1\n2.6\n5.6\n1.4\nvirginica\n\n\n135\n7.7\n3.0\n6.1\n2.3\nvirginica\n\n\n136\n6.3\n3.4\n5.6\n2.4\nvirginica\n\n\n137\n6.4\n3.1\n5.5\n1.8\nvirginica\n\n\n138\n6.0\n3.0\n4.8\n1.8\nvirginica\n\n\n139\n6.9\n3.1\n5.4\n2.1\nvirginica\n\n\n140\n6.7\n3.1\n5.6\n2.4\nvirginica\n\n\n141\n6.9\n3.1\n5.1\n2.3\nvirginica\n\n\n142\n5.8\n2.7\n5.1\n1.9\nvirginica\n\n\n143\n6.8\n3.2\n5.9\n2.3\nvirginica\n\n\n144\n6.7\n3.3\n5.7\n2.5\nvirginica\n\n\n145\n6.7\n3.0\n5.2\n2.3\nvirginica\n\n\n146\n6.3\n2.5\n5.0\n1.9\nvirginica\n\n\n147\n6.5\n3.0\n5.2\n2.0\nvirginica\n\n\n148\n6.2\n3.4\n5.4\n2.3\nvirginica\n\n\n149\n5.9\n3.0\n5.1\n1.8\nvirginica\n\n\n\n\n\n\n\nQ4 Use eval for Calculations - Create a new column petal_area using the formula:\npetal_area = petal_length * petal_width - Display the top 5 flowers with the largest petal_area. - Use query to filter flowers that meet the following conditions: - petal_area &gt; 10 - sepal_length is in the range 5 to 7.\n\niris.eval('petal_area = (petal_length*petal_width)', inplace = True)\n\ntop_5_flowers = iris.sort_values(by = 'petal_area', ascending=False).head(5)\ntop_5_flowers\n\n#next sub-question done in next cell as \"top_5_flowers\" werent being displayed properly using print\n\n\n\n\n\n\n\n\nsepal_length\nsepal_width\npetal_length\npetal_width\nspecies\npetal_area\n\n\n\n\n118\n7.7\n2.6\n6.9\n2.3\nvirginica\n15.87\n\n\n109\n7.2\n3.6\n6.1\n2.5\nvirginica\n15.25\n\n\n100\n6.3\n3.3\n6.0\n2.5\nvirginica\n15.00\n\n\n117\n7.7\n3.8\n6.7\n2.2\nvirginica\n14.74\n\n\n144\n6.7\n3.3\n5.7\n2.5\nvirginica\n14.25\n\n\n\n\n\n\n\n\nfiltered_iris = iris.query(\"petal_area &gt; 10\" and \" 5 &lt;= sepal_length &lt;= 7\")\nfiltered_iris\n\n\n\n\n\n\n\n\nsepal_length\nsepal_width\npetal_length\npetal_width\nspecies\npetal_area\n\n\n\n\n0\n5.1\n3.5\n1.4\n0.2\nsetosa\n0.28\n\n\n4\n5.0\n3.6\n1.4\n0.2\nsetosa\n0.28\n\n\n5\n5.4\n3.9\n1.7\n0.4\nsetosa\n0.68\n\n\n7\n5.0\n3.4\n1.5\n0.2\nsetosa\n0.30\n\n\n10\n5.4\n3.7\n1.5\n0.2\nsetosa\n0.30\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n145\n6.7\n3.0\n5.2\n2.3\nvirginica\n11.96\n\n\n146\n6.3\n2.5\n5.0\n1.9\nvirginica\n9.50\n\n\n147\n6.5\n3.0\n5.2\n2.0\nvirginica\n10.40\n\n\n148\n6.2\n3.4\n5.4\n2.3\nvirginica\n12.42\n\n\n149\n5.9\n3.0\n5.1\n1.8\nvirginica\n9.18\n\n\n\n\n116 rows × 6 columns\n\n\n\nQ5 Analyze and Visualize - Perform a group-wise analysis: 1. Calculate the average petal length for each species. 2. Find the count of flowers for each species. 3. Create a scatter plot of sepal_length vs. petal_length, colored by species.\n\naverage_petal_length = iris.groupby(\"species\")[\"petal_length\"].mean()\ncount_flowers = iris.groupby(\"species\").size()\n\nprint(f\"The average petal length for each species: \\n{average_petal_length}\\n\")\nprint(f\"The count of each flower: \\n{count_flowers}\\n\")\n\n#scatterplot\n\nsns.scatterplot(x = iris['sepal_length'], y = iris['petal_length'], hue = iris[\"species\"])     #used seaborn as matplotlib doesnt have hue argument\n\nplt.xlabel('Sepal Length')\nplt.ylabel('Petal Length')\nplt.title('Sepal Length vs. Petal Length')\nplt.legend()\nplt.grid(True)\nplt.show()\n\nThe average petal length for each species: \nspecies\nsetosa        1.462\nversicolor    4.260\nvirginica     5.552\nName: petal_length, dtype: float64\n\nThe count of each flower: \nspecies\nsetosa        50\nversicolor    50\nvirginica     50\ndtype: int64"
  },
  {
    "objectID": "posts/Assignment_2_Pandas_Matplotlib.html#matplotlib-basic-plotting-questions",
    "href": "posts/Assignment_2_Pandas_Matplotlib.html#matplotlib-basic-plotting-questions",
    "title": "1. Basic Operations",
    "section": "7. Matplotlib: Basic Plotting Questions",
    "text": "7. Matplotlib: Basic Plotting Questions\nQ1. Line Plot\nPlot a sine wave ((y = sin(x))) for (x in [0, 2π]). Customize the plot by: 1. Adding a title to the graph. 2. Adding labels for the x-axis and y-axis. 3. Displaying a grid.\n\nfig, ax  = plt.subplots()\nangles = np.linspace(0, 2*np.pi, 10000)\nsin_fn = np.sin(angles)\n\nax.plot(angles, sin_fn, color = 'r')\nax.set_title(\"Sine Wave\", fontsize = 14)\nax.set_xlabel(\"Angles\")\nax.set_ylabel(\"Sine values\")\nax.grid(True)\n\n\n\n\n\n\n\n\nQ2. Multiple Line Plots\nPlot the following functions on the same graph for (x ): 1. (y_1 = sin(x)) 2. (y_2 = cos(x))\nCustomize the graph by: - Using different colors and line styles for each function. - Adding a legend to identify the curves.\n\nfig, ax  = plt.subplots()\nangles = np.linspace(0, 2*np.pi, 10000)\n\nsin_fn = np.sin(angles)\ncos_fn = np.cos(angles)\n\nax.plot(angles, sin_fn, label = \"$sin(x)$\", linestyle = \"-\", color = 'b')\nax.plot(angles, cos_fn, label = \"$cos(x)$\", linestyle = \"--\", color = 'r')\nax.set_title(\"Sine and Cosine Waves\", fontsize = 14)\nax.set_xlabel(\"Angles\")\nax.set_ylabel(\"Sine and cosine values\")\nax.legend(bbox_to_anchor = (1, 1), title = \"Functions\")                         # bbox_to_anchor = (1, 1) to display legend outside the plot.\nax.grid(True)\n\n\n\n\n\n\n\n\nQ3. Plot Customization\nPlot the function (y = x^2) for (x ).\nCustomize the plot by: 1. Adding a title and axis labels. 2. Changing the line style, color, and thickness. 3. Adjusting the axis limits to make the graph more visually appealing.\n\nfig, ax  = plt.subplots()\n\nx = np.linspace(-100, 100, 1000)\ny = x**2\n\nax.plot(x, y, linestyle = \"-.\", linewidth = 4, color = 'r')\n\nax.set_title(\"Plot of $y = x^2$\", fontsize = 14)\nax.set_xlabel('$x$')\nax.set_ylabel('$y^2$')\nax.set_xlim(-10, 10)\nax.set_ylim(-5, 110)\n\nplt.show()"
  },
  {
    "objectID": "posts/Assignment_2_Pandas_Matplotlib.html#a.-bar-plot",
    "href": "posts/Assignment_2_Pandas_Matplotlib.html#a.-bar-plot",
    "title": "1. Basic Operations",
    "section": "8a. Bar Plot",
    "text": "8a. Bar Plot\nQ1 You are provided with the tips dataset. Your task is to create a bar plot** using Matplotlib.**\n\nLoad the tips dataset using Seaborn:\nimport seaborn as sns\ntips = sns.load_dataset('tips')\nCreate a bar plot showing the average tip for each day of the week. Label the x-axis as Day, the y-axis as Average Tip, and add a title: “Average Tip by Day”.\nBased on the bar plot, which day has the highest average tip?\n\n\ntips = sns.load_dataset('tips')\naverage_tips = tips.groupby(\"day\").tip.mean()\nbars = average_tips.plot(kind='bar', color='skyblue', edgecolor = 'k', figsize=(8, 6), xlabel='Day', ylabel='Average tips', title='Average Tips on Each Day')\n\nprint(f\"The day which ahs the highest average tip is: {average_tips.idxmax()}\\n\")\n\nThe day which ahs the highest average tip is: Sun\n\n\n\n\n\n\n\n\n\n\nBased on the bar-plot above the Sunday has the highest average tip"
  },
  {
    "objectID": "posts/Assignment_2_Pandas_Matplotlib.html#b.-scatter-plot",
    "href": "posts/Assignment_2_Pandas_Matplotlib.html#b.-scatter-plot",
    "title": "1. Basic Operations",
    "section": "8b. Scatter Plot",
    "text": "8b. Scatter Plot\nQ1. You are provided with the tips dataset. Your task is to create a scatter plot using Matplotlib.\n\nLoad the tips dataset using Seaborn:\nimport seaborn as sns\ntips = sns.load_dataset('tips')\nCreate a scatter plot with total_bill on the x-axis and tip on the y-axis.\nLabel the x-axis as Total Bill, the y-axis as Tip, and add a title: “Relationship between Total Bill and Tip”.\nBased on the scatter plot, do you observe any relationship between total_bill and tip?\n\n\ntips = sns.load_dataset('tips')\n\nfig, ax = plt.subplots()\ntips.plot.scatter(x='total_bill', y='tip', c='size',colormap = 'viridis', s = tips['size']*10, ax = ax, xlabel = \"Total bill\", ylabel = \"Tip\",title = \"Relationship between Total Bill and Tip\")\n\nplt.show()\n\n\n\n\n\n\n\n\nThere appears to be a positive relationship between total_bill and tip. As the total bill increases, the tip generally tends to increase as well. However, the relationship does not appear to be perfectly linear, and there is some variability in the amount of tip given for a given total bill"
  },
  {
    "objectID": "posts/Assignment_2_Pandas_Matplotlib.html#matplotlib-subplots-and-layouts",
    "href": "posts/Assignment_2_Pandas_Matplotlib.html#matplotlib-subplots-and-layouts",
    "title": "1. Basic Operations",
    "section": "9. Matplotlib: Subplots and Layouts",
    "text": "9. Matplotlib: Subplots and Layouts\nQ1. Create a 2x2 grid of subplots with: - Subplot (1,1): Plot y = sin(x). - Subplot (1,2): Plot y = cos(x) . - Subplot (2,1): Plot y = e−x - Subplot (2,2): Plot y=ln(x) for x∈[0.1,2].\nCustomize background colors, add unique x and y labels, and set titles.\n\n\nfig, ax = plt.subplots(2, 2, figsize = (10, 6))\n\n\n\nx_1 = np.linspace(0, 2*np.pi, 10000)\ny_1 = np.sin(x_1)\nx_2 = np.linspace(0.1, 2, 10000)\ny_2 = np.cos(x_1)\ny_3 = np.exp(-(x_1))\ny_4 = np.log(x_2)\n\nax[0, 0].plot(x_1, y_1, color = 'C0')\nax[0, 0].set_title(\"$sin(x)$\", fontsize = 14)\nax[0, 0].set_xlabel(\"$x$\")\nax[0, 0].set_ylabel(\"$sin(x)$\")\nax[0, 0].set_facecolor('lightyellow')\n\nax[0, 1].plot(x_1, y_2, color = 'C1')\nax[0, 1].set_title(\"$cos(x)$\", fontsize = 14)\nax[0, 1].set_xlabel(\"$x$\")\nax[0, 1].set_ylabel(\"$cos(x)$\")\nax[0, 1].set_facecolor('lightblue')\n\nax[1, 0].plot(x_1, y_3, color = 'C2')\nax[1, 0].set_title(\"$e^{-x}$\", fontsize = 14)\nax[1, 0].set_xlabel(\"$x$\")\nax[1, 0].set_ylabel(\"$e^{-x}$\")\nax[1, 0].set_facecolor('orange')\n\n\nax[1, 1].plot(x_2, y_4, color = 'C3')\nax[1, 1].set_title(\"$log(x)$\", fontsize = 14)\nax[1, 1].set_xlabel(\"$x$\")\nax[1, 1].set_ylabel(\"$log(x)$\")\nax[1, 1].set_facecolor('lightgreen')\n\nfig.tight_layout()\n\n\n\n\n\n\n\n\nQ2. Create a subplot within another subplot: - Main subplot: Display a scatter plot of 100 random points with x and y values between 0 and 1. - Inset subplot: Display a histogram of the x-values from the scatter plot.\n\nfig, main_ax = plt.subplots()\narr_x = np.random.rand(100)\narr_y = np.random.rand(100)\ncolors = arr_x\nmain_ax.scatter(arr_x, arr_y, c = colors, cmap = \"viridis\")\nmain_ax.set_title(\"Scatter Plot of Random Numbers\", fontsize = 14)\n\ninset_ax = fig.add_axes([0.6, 0.6, 0.25, 0.25])\ninset_ax.hist(arr_x, bins = 50, color = 'r', edgecolor = 'k')\ninset_ax.set_title(\"Histogram of X Values\")\nfig.tight_layout()\n\n\n\n\n\n\n\n\nQ3. Create a Layout with One Large and Two Smaller Subplots\n\nDesign a large subplot occupying the top two-thirds of the figure and plot ( y = sin(x) ) and ( y = cos(x) ) on the same graph.\nCreate two smaller subplots in the bottom row:\n\nOn the left, plot y =x2.\n\nOn the right, plot y = ex.\n\n\nEnsure each subplot has appropriate titles, axis labels, and legends where necessary. Use a clean layout that avoids overlapping elements.\n\nfig_1, ax = plt.subplots(figsize = (10, 6))\nangles = np.linspace(0, 2*np.pi, 10000)\n                    \nsin_fn = np.sin(angles)\ncos_fn = np.cos(angles)\n\nax.plot(angles, sin_fn, label = \"$sin(x)$\", color = 'b')\nax.plot(angles, cos_fn, label = \"$cos(x)$\", color = 'r')\nax.set_title(\"Sine and Cosine Waves\", fontsize = 14)\nax.legend(bbox_to_anchor = (1, 1), title = \"Functions\")\n\nfig, ax_2 = plt.subplots(1, 2, figsize = (10, 6))\nx = np.linspace(-10, 10, 10000)\ny_1 = x**2\ny_2 = np.exp(x)\n\nax_2[0].plot(x, y_1, color = 'k')\nax_2[0].set_title(\"$y=x^2$\", fontsize = 14)\nax_2[0].set_xlabel(\"$x$\")\nax_2[0].set_ylabel(\"$x^2$\")\nax_2[1].plot(x, y_2, color = 'C0')\nax_2[1].set_title(\"$y=e^x$\", fontsize = 14)\nax_2[1].set_xlabel(\"$x$\")\nax_2[1].set_ylabel(\"$e^x$\")\n\nplt.tight_layout()"
  },
  {
    "objectID": "posts/Assignment_2_Pandas_Matplotlib.html#matplotlib-advanced-customization",
    "href": "posts/Assignment_2_Pandas_Matplotlib.html#matplotlib-advanced-customization",
    "title": "1. Basic Operations",
    "section": "10. Matplotlib: Advanced Customization",
    "text": "10. Matplotlib: Advanced Customization\nQ1. Customizing Axes and Ticks\nCreate a line plot for y = x^2 in the range -10 to 10. Customize the axes and ticks: 1. Set x-axis range to -10 to 10. 2. Set y-axis range to 0 to 100. 3. Use custom tick marks at intervals of 2 for x-axis and 10 for y-axis. 4. Rotate x-axis tick labels by 45 degrees.\n\nfig, ax  = plt.subplots()\nx = np.linspace(-10, 10, 100)\ny = x**2\n\nax.plot(x, y, linewidth = 2, color = 'r')\n\nax.set_title(\"Plot of $y = x^2$\", fontsize = 14)\nax.set_xlim(-10, 10)\nax.set_ylim(0, 100)\nax.set_xticks(np.arange(-10, 10, 2))\nax.set_yticks(np.arange(0, 100, 10))\nax.tick_params(axis = 'x', rotation = 45)\nax.set_xlabel('$x$')\nax.set_ylabel('$y^2$')\n\nplt.show()\n\n\n\n\n\n\n\n\nQ2. Multiple Subplots with Shared Legend and Grid Customization\nCreate a figure with four subplots (2x2 grid) showing different trigonometric functions: 1. Top-left: y = sin(x) 2. Top-right: y = cos(x) 3. Bottom-left: y = tan(x) (restrict x to avoid undefined regions). 4. Bottom-right: y = sin^2(x) + cos^2(x) (should always equal 1).\n\nfig, ax = plt.subplots(2, 2, figsize = (10, 6))\nx_1 = np.linspace(-2*np.pi, 2*np.pi, 10000)\ny_1 = np.sin(x_1)\ny_2 = np.cos(x_1)\ny_3 = np.tan(x_1)\ny_4 = (np.sin(x_1))**2 + (np.cos(x_1))**2\n\nax[0, 0].plot(x_1, y_1, color = 'C0')\nax[0, 0].set_title(\"$sin(x)$\", fontsize = 14)\nax[0, 0].set_xlabel(\"$x$\")\nax[0, 0].set_ylabel(\"$sin(x)$\")\n\nax[0, 1].plot(x_1, y_2, color = 'C1')\nax[0, 1].set_title(\"$cos(x)$\", fontsize = 14)\nax[0, 1].set_xlabel(\"$x$\")\nax[0, 1].set_ylabel(\"$cos(x)$\")\n\nax[1, 0].set_ylim(-20, 20)\nax[1, 0].plot(x_1, y_3, color = 'C2')\nax[1, 0].set_title(\"$tan(x)$\", fontsize = 14)\nax[1, 0].set_xlabel(\"$x$\")\nax[1, 0].set_ylabel(\"$tan(x)$\")\nax[1,0].set_xlim(-np.pi/2,np.pi/2)   #bound from -pi/2 to pi/2 to avoid the discontinuity \n\nax[1, 1].plot(x_1, y_4, color = 'C3')\nax[1, 1].set_title(\"${sin(x)}^2 + {cos(x)}^2$\", fontsize = 14)\nax[1, 1].set_xlabel(\"$x$\")\nax[1, 1].set_ylabel(\"${sin(x)}^2 + {cos(x)}^2$\")\n\nfig.tight_layout()\n\n\n\n\n\n\n\n\nQ3. Subplots and Shared Axes\nCreate two subplots side-by-side: 1. Bar chart for sales (random data) from January to June. 2. Line chart for cumulative sales. Share the y-axis and add titles, a common x-axis label, and a grid for the second plot.\n\n#using example csv file named sales_data.csv\n\nsales_df = pd.read_csv (\"sales_data.csv\")\ncum_sales = np.cumsum(sales_df[\"Sales\"])\n\nfig,ax = plt.subplots(1,2,sharey = True)\n\nax[0].bar(sales_df[\"Month\"],sales_df[\"Sales\"])\nax[0].set_xticklabels(sales_df[\"Month\"],rotation = -45)\nax[0].grid(True)\nax[0].set_ylabel(\"SALES\")\n\nax[1].plot(sales_df[\"Month\"],cum_sales)\nax[1].set_xticklabels(sales_df[\"Month\"],rotation = -45)\nax[1].grid(True)\n\nfig.supxlabel(\"MONTHS\")\nfig.tight_layout()\n\n\n\n\n\n\n\n\nQ4. Adding Annotations\nCreate a scatter plot of 10 random points: 1. Annotate the point with the max y-coordinate with a red star and text label. 2. Customize marker size and color for all points.\n\nfig, ax = plt.subplots()\nx = np.random.rand(10)\ny = np.random.rand(10)\n\nax.scatter(x, y, color = 'b', marker = 'o')\n\nmax_y_ind = np.argmax(y)\nmax_y_coordinate = y[max_y_ind]\nmax_x_coordinate = x[max_y_ind]\n\nax.scatter(max_x_coordinate, max_y_coordinate, color = 'r', marker = '*', s = 200)\nax.text(max_x_coordinate, max_y_coordinate, f\"({max_x_coordinate:.2f}, {max_y_coordinate:.2f})\", fontsize=10, color='red', ha='left', va='bottom')\n\nplt.show()\n\n\n\n\n\n\n\n\nQ5. Creating a Custom Colormap\nGenerate a heatmap for a 5x5 matrix of random numbers between 0 and 1: 1. Use a custom colormap (blue to red). 2. Add a color bar and display exact cell values rounded to 2 decimals.\n\nmatrix = np.random.rand(5, 5)\n\nfig, ax = plt.subplots()\ncustomized_cmap = LinearSegmentedColormap.from_list(\"blue_rea\", [\"blue\", \"red\"])\nsns.heatmap(matrix, cmap = customized_cmap, annot = True, fmt = '.2f', square = True)\n\nax.set_title(\"Heatmap for Random Numbers\", fontsize =  14)\nplt.show()\n\n\n# im = ax.imshow(matrix, cmap = customized_cmap)\n# fig.colorbar(im, ax = ax)\n# for i in range(5):\n#     for j in range(5):\n#         ax.text(j, i, f'{matrix[i, j]:.2f}', ha='center', va='center', color='black', fontsize=10)\n\n\n\n\n\n\n\n\nQ6. Customization of 3D Plot\nUsing Matplotlib’s mpl_toolkits.mplot3d, create a 3D surface plot for the function: z = sin(sqrt(x^2 + y^2))\nRequirements: 1. Generate x and y values in the range -5 to 5 using a meshgrid. 2. Use a custom colormap that highlights peaks and valleys (e.g., coolwarm). 3. Add a color bar with a label “Amplitude”. 4. Add labels for all three axes and a title. 5. Rotate the 3D plot to a custom viewing angle using ax.view_init.\n\nfig, ax = plt.subplots(subplot_kw = {\"projection\": \"3d\"})\nx = np.linspace(-5, 6)\ny = np.linspace(-5, 6)\nX, Y = np.meshgrid(x,y)\nZ = np.sin((X**2 + Y**2)**(1/2))\n\nsurface = ax.plot_surface(X, Y, Z, cmap = 'coolwarm')\n\nax.set_title('3D Plot', fontsize=14)\nax.set_xlabel('X-axis')\nax.set_ylabel('Y-axis')\nax.set_zlabel('Z-axis')\n\nax.view_init(azim = 15)\nfig.colorbar(surface, label = \"Amplitude\", pad = 0.2)\n\nplt.show()"
  },
  {
    "objectID": "posts/Assignment_2_Pandas_Matplotlib.html#extra-questions",
    "href": "posts/Assignment_2_Pandas_Matplotlib.html#extra-questions",
    "title": "1. Basic Operations",
    "section": "EXTRA QUESTIONS",
    "text": "EXTRA QUESTIONS"
  },
  {
    "objectID": "posts/Assignment_2_Pandas_Matplotlib.html#definition-of-a-partition",
    "href": "posts/Assignment_2_Pandas_Matplotlib.html#definition-of-a-partition",
    "title": "1. Basic Operations",
    "section": "Definition of a Partition",
    "text": "Definition of a Partition\nA collection of sets \\({A_1, , A_n}\\) is a partition of the universal set \\(\\) if it satisfies the following conditions:\n\nNon-overlap: \\({A_1, , A_n}\\) is disjoint.\nDecompose: \\(A_1 A_2 A_n = \\)."
  },
  {
    "objectID": "posts/Assignment_2_Pandas_Matplotlib.html#important-laws",
    "href": "posts/Assignment_2_Pandas_Matplotlib.html#important-laws",
    "title": "1. Basic Operations",
    "section": "Important Laws",
    "text": "Important Laws\n\nDistributive (How to mix union and intersection)\n\\[\nA \\cap (B \\cup C) = (A \\cap B) \\cup (A \\cap C)\n\\]\n\\[\nA \\cup (B \\cap C) = (A \\cup B) \\cap (A \\cup C)\n\\]\n\n\n\nDe Morgan’s Law (How to complement over intersection and union)\n\\[\n(A \\cap B)^c = A^c \\cup B^c\n\\]\n\\[\n(A \\cup B)^c = A^c \\cap B^c\n\\]\nQuestion 1: Function to Check Partition\nWrite a Python function to check if a given list of sets is a partition of a universal set. The function should take the universal set and the list of sets as arguments and verify the following conditions: 1. The union of all subsets in the list equals the universal set. 2. The subsets are pairwise disjoint.\nWrite your function and test it with an example.\n\n\ndef is_partition(sets, universal_set) : \n    \n    union_of_sets = set().union(*sets)       #Union of all sets in the list\n    if union_of_sets != universal_set:       #This will check the first required condition\n        return False \n\n    for i in range(len(sets)):\n        for j in range(len(sets)):\n            if len(np.intersect1d(sets[i], sets[j])) != 0 and i != j:  #This will check the second condition and will return false as soon as any pair of sets are disjoint \n                return False\n    return True                              #If both the conditions are true then in the end the function will return true \n\n#testing the function with examples\n\n# Example 1\n\nuniversal_set = {1, 2, 3, 4}\nsets_1 = [{1, 2}, {3}, {4}]\nprint(is_partition(sets_1, universal_set))  \n\n# Example 2: sets are not disjoint\n\nsets_2 = [{1, 2}, {2, 3}, {4}, {2, 1}]\nprint(is_partition(sets_2, universal_set))  \n\n# Example 3:union is not universal set\nsets_3 = [{1, 2}, {5, 6}, {7}]\n\nprint(is_partition(sets_3, universal_set))  \n\nTrue\nFalse\nFalse\n\n\nQuestion 2: Laws\nWith an example numpy array corresponding to set A, B, C, show the distributive properties and De Morgan’s Laws.\nAlso, use venn3 from matplotlib_venn library for vizualization.\n\nfrom matplotlib_venn import venn3\n\nA = np.array([1, 3, 2, 10, 6, 9])\nB = np.array([5, 3, 17, 10, 8, 9])\nC = np.array([4, 72, 23, 10, 34, 7])\n\nuniversal_set = np.union1d(A, np.union1d(B, C))\n\nA_intrsct_B = np.intersect1d(A, B)\nA_intrsct_C = np.intersect1d(A, C)\nB_intrsct_C = np.intersect1d(C, B)\n\nA_uni_B = np.union1d(A,B)\nC_uni_B = np.union1d(C,B)\nC_uni_A = np.union1d(C,A)\n\nA_intrsct_B_uni_C = np.intersect1d(A, C_uni_B)\nA_uni_B_intrsct_C = np.union1d(A, B_intrsct_C)\n\n\ndef negation(set_a):\n    neg_set_a = universal_set[~np.isin(universal_set, set_a)]                    \n    return neg_set_a                           # ~np.isin(universal_set, set_a) returns a boolean mask. The value is true for the elements which are in U-set_a.\n\n\ndef check_distributive(A, B, C):\n\n    # here we can't directly compare two arrays with ==. As it operates element wise and return a array of boolean values\n    \n    if np.array_equal(A_intrsct_B_uni_C, np.union1d(A_intrsct_B, A_intrsct_C)) and np.array_equal(A_uni_B_intrsct_C, np.intersect1d(A_uni_B, C_uni_A)):\n        return True                                         \n    return False\n\n\ndef check_morgan_law(A, B, C):\n  \n  if np.array_equal(negation(A_intrsct_B), np.union1d(negation(A), negation(B))) and np.array_equal(negation(A_uni_B), np.intersect1d(negation(A), negation(B))):\n    return True  \n  return False\n\n\nprint(f\"Checking if the distributive properties are true : {check_distributive(A, B, C)}\\n\")\nprint(f\"Checking if the morgan law is true : {check_morgan_law(A, B, C)}\\n\")\n\nvenn = venn3(subsets = (A, B, C), set_labels=('Set A', 'Set B', 'Set C'))\n\nvenn.get_label_by_id('100').set_text('Only A')                                  # Label for Set A only\nvenn.get_label_by_id('010').set_text('Only B')                                  # Label for Set B only\nvenn.get_label_by_id('001').set_text('Only C')                                  # Label for Set C only\nvenn.get_label_by_id('110').set_text('$A \\cap B$')                               \nvenn.get_label_by_id('011').set_text('$B \\cap C$')                              #using latex \nvenn.get_label_by_id('101').set_text('$A \\cap C$')\nvenn.get_label_by_id('111').set_text('$A \\cap B \\cap C$')\n\nplt.show()\n\nChecking if the distributive properties are true : True\n\nChecking if the morgan law is true : True\n\n\n\n\n\n\n\n\n\n\nQuestion 3: Union and Intersection of Students\nFor below code: 1. The union of all sets of students present across the three subjects. 2. The intersection of all sets of students present across the three subjects.\nimport pandas as pd\n# Dictionary of marks\nmarks = {\n    \"Math\": {\"Alice\": 85, \"Bob\": 90, \"Charlie\": 78},\n    \"Physics\": {\"Bob\": 88, \"Charlie\": 92, \"David\": 75},\n    \"Chemistry\": {\"Alice\": 82, \"Charlie\": 80, \"Eve\": 91},\n}\n\n\n# Convert the dictionary to a DataFrame\ndf = pd.DataFrame(marks).T\n\nimport pandas as pd\n# Dictionary of marks\nmarks = {\n    \"Math\": {\"Alice\": 85, \"Bob\": 90, \"Charlie\": 78},\n    \"Physics\": {\"Bob\": 88, \"Charlie\": 92, \"David\": 75},\n    \"Chemistry\": {\"Alice\": 82, \"Charlie\": 80, \"Eve\": 91},\n}\n\n\n# Convert the dictionary to a DataFrame\ndf = pd.DataFrame(marks) .T\n\nunion_of_students = set(df.columns)\nprint(f\"The union of all sets of students present across the three subjects is: {union_of_students}\\n\") \n\nintersection_of_student = set(df.dropna(axis=1))\nprint(f\"The intersection of all sets of students present across the three subjects is: {intersection_of_student}\\n\")\n\nThe union of all sets of students present across the three subjects is: {'David', 'Charlie', 'Bob', 'Alice', 'Eve'}\n\nThe intersection of all sets of students present across the three subjects is: {'Charlie'}\n\n\n\nQuestion 4\nImplement a Python function to compute the cartesian product of two sets A and B without using Python’s built-in functions or libraries like itertools. The function should return the cartesian product as a set of ordered pairs (tuples).\n\ndef cartesian_product(a_set, b_set):\n\n    answer = set()\n     \n    for element_a in a_set:\n        for element_b in b_set:\n            answer.add((element_a, element_b))\n    return answer\n\n\n#testing the function with examples\n\nA = {1, 2, 3}\nB = {3, 4}\nprint(cartesian_product(A, B),\"\\n\") \n\nA = {'a', 'b'}\nB = {1, 2}\nprint(cartesian_product(A, B),\"\\n\")  \n\nA = {}\nB = {10, 20, 30}\nprint(cartesian_product(A, B))   #this should print a null set \n\n{(2, 4), (3, 4), (1, 4), (2, 3), (3, 3), (1, 3)} \n\n{('a', 2), ('b', 1), ('b', 2), ('a', 1)} \n\nset()"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Quarto Template",
    "section": "",
    "text": "Quarto template Text!"
  }
]